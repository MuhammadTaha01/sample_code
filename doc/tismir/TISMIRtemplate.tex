%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for TISMIR Papers
% 2017 version, based on previous ISMIR conference template
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sample Document LaTeX packages
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc}
\usepackage{tismir}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{lipsum}
\usepackage{forest}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title and Author information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{QawalRang: A dataset for genre classification of Qawalis}
%
\author{%
Faheem Sheikh}%

\date{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Additional Paper Information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Article Type - Uncomment and modify, if necessary.
% Accepted values: research, overview, and dataset
\type{dataset}

% Citation in First Page
%
% "Mandatory" (if missing will print the complete list of authors,
% including the \thanks symbols)
\authorref{Sheikh,~F.}
%
% (Optional)
% \journalyear{2017}
% \journalvolume{V}
% \journalissue{N}
% \journalpages{xx--xx}
% \doi{xx.xxxx/xxxx.xx}

% Remaining Pages (Optional)
%
\authorshort{Sheikh, ~F.} %or, e.g., \authorshort{Author1 et al}
% \titleshort{Template for TISMIR}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document Content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\twocolumn[{%
%
\maketitleblock
%
\today
%

\begin{abstract}
A new dataset containing 72 Qawali songs of one-minute duration along with tagged metadata is presented. Majority of samples in the dataset exhibit strong similarity in the fundamental musical properties. This is demonstrated by using the dataset for Qawali genre detection against popular western music genres. Qawali detection is a hueristic based unsupervised genre classification algorithm is based on source separation of two major components typical of Qawali performances namely tabla and taali. The algorithm shows a mean accuracy across genres of more than 90\% with a recall of more than 76\%. Dataset release is accompanined with python programs used to construct and extend the dataset as well as reproducuing the results presented in this study. \end{abstract}
%
\begin{keywords}
genre, classification, qawali, dataset, tabla, taali
\end{keywords}
}]
\saythanks{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Main Content Start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}\label{sec:intro}
Qawalis have a long and historic tradition in indian subcontinent, by some accounts they go back to at least 13th century. Indian music traditionally has developed with musical families and one of the foremost musical families "Qawal Baccha Ghrana" \citep{JayashreeBhat} is credited with refining this singing form as distinctive genre. They have been used to recite devotional songs, have been sung by groups in shrines. Even today they are popular in Indian subcontinent with performances given on happy occassions, part of songs  in films as well as religious commemorations. 

Qawalis incorporate both classical and modern musical elements, but almost all performances are characteristed by two fold beat elements a tabla which is the primary rythym elemnet and periodic clapping by backing vocals called "taali".

Introudce genre detection as a problem, reference to MIREX tasks and literature survery of genre classification of non-western music

Review of organization of rest of the paper.

\section{Dataset}\label{sec:data}
Songs in QawalRang dataset have been sourced from personal collection, web-crawling and popular music streaming online platforms like youtube. The selection criterion behind including a song was based on following points.
\begin{itemize}
\item Song is performed by well-known/renowed Qawal parties/groups. This is to remove any doubts about labeleling. Ofcourse this has to traded-off against diversity of performers.
\item Songs start with a introductory section including both tabla and taali components. In a very small minority of cases where songs start with a vocal improvisation but does contains segments with tabla and taali components at a later timepoint, that snippet is included.
\item Songs performed in classical/semi-classical pattern have been preferred, this makes QawalRang dataset unique and reduces overlapp with other common genre like pop and rock. For this reason songs that follow a modern mixture of qawali with mainstream music are avoided.
\end{itemize}

All songs included in the dataset are described by a metadata file of key-value pairs. The key-values are governed by a json schema which defines the following keys:
\begin{enumerate}
\item ID: unique identifier of the song in the data-set
\item name: song's original/descriptive name
\item artist: performer's or Qawal party's name
\item location: URL for the full song
\item start: Timestamp in seconds within origianl song from where snippet was taken
\item duration: Duration of song snippet in seconds
\end{enumerate}

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{sources}
  \caption{QawalRang: Distribution by sources}
\label{fig:src_dist}
\end{figure}
Above metadata description allows easy experimentation and even extension of the dataset. Accompying the dataset is a python program which can (re)construct QawalRang dataset or a section of it by reading the metadata file on the fly. The program supports both offline and oneline modes with the former meaning that songs are not downloaded upon building the dataset
\begin{figure}[htbp]
  \centering
  \includegraphics[height=4cm, width=0.95\columnwidth]{artist}
  \caption{QawalRang: Distribution by artist/performer}
\label{fig:author_dist}
\end{figure}

\section{Qawali Genre Detector}\label{sec:detector}

The proposed Qawali genre classification consists of two stages, a feature extraction and a binary classification stage. The overall scheme works on the principle that typical Qawali performances start with a preamble segment in which with rythym is driven by tabla and beat controlled by periodic clapping. The feature extractor aims to separate tabla and taali components from the raw audio data, and then computes CQT and MFCC features respectively from these sources It then uses heuristics for pitch energy and local mfcc extrema points to reach a binary classification decision for qawali. This proposed system is shown in figure \ref{fig:figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.5, width=0.95\columnwidth]{qawali_detector}
  \caption{Qawali genre detector.}
\label{fig:figure}
\end{figure}

\subsection{Feature extractor}
Features are extracted from raw audio spectrogram after separating the audio in potential tabla/taali source spectrograms. Let $\boldsymbol{S}$ be an $txm$ audio spectrum matrix decomposed into sorted feature matrix $\boldsymbol{W}$ and coefficients matrix $\boldsymbol{H}$ each of dimensions $txn$ and $nxm$ respectively with non-negative matrix factorization, where $n$ is the number of independent music sources the song is composed of.

\begin{align}\label{eq:eq1}
\boldsymbol{S} = \boldsymbol{W}.\boldsymbol{H}
\end{align}

We select $l \in (0,n)$ to extract Tabla spectrogram $\boldsymbol{S}_{B}$ 

\begin{align}\label{eq:eq2}
\boldsymbol{S}_{B} = \boldsymbol{W}_{B}.\boldsymbol{H}_{B}
\end{align}
where
\begin{align}\label{eq:eq3}
\boldsymbol{W}_{B} = [\boldsymbol{W}.\boldsymbol{u}_{l} ...]
\end{align}
and 
\begin{align}\label{eq:eq4}
\boldsymbol{H}_{B} = [\boldsymbol{u}_{l}^T.\boldsymbol{H} ...]
\end{align}
with $u_{l}$ being a unit column vector from Identity matrix $\boldsymbol{I}$ with size $txt$. In other words spectrogram for tabla source is simply computed
by selecting columns/rows from feature matrix $\boldsymbol{H}$ and coefficient matrix $\boldsymbol{W}$. Similary taali spectrogram $\boldsymbol{S}_{T}$ can be written as:
\begin{align}\label{eq:eq5}
\boldsymbol{S}_{T} = \boldsymbol{W}_{T}.\boldsymbol{H}_{T}
\end{align}

Feature-set for genre detection is then CQT power for the tabla source matrix, obtained by mapping CQT from tabla spectrogram and taking norm/energy along second dimension. This transforms the tabla spectrogram matrix into a feature vector represented by:
\begin{align}\label{eq:eq6}
\boldsymbol{f}_{CQT} = \lvert \lvert f\colon \boldsymbol{S}_{B}\to CQT \rvert \rvert
\end{align}

For tabla source a median MFCC vector is computed by obtaining normalized mfcc vector from taali spectrogram:
\begin{align}\label{eq:eq7}
\boldsymbol{f}_{MFCC} = med(\frac{f\colon \boldsymbol{S}_{T}\to MFCC}{\lvert \lvert {f\colon \boldsymbol{S}_{T}\to MFCC} \rvert \rvert})
\end{align}

\subsection{Binary Classifier}
Based on tabla/taali features, binary classification on whether the given song can be qualified as qawali or not is based on the following individual deicisions.
\begin{itemize}
	\item Tabla detector (\textbf{TD}): Does $\boldsymbol{f}_{CQT}$ represent a tabla source? Result is a non-binary decision with three possibilities\textit{yes(Y)/No(N)/Maybe(M)}.
	\item TaaLi detector (\textbf{LD}): Does $\boldsymbol{f}_{MFCC}$ represents a taali source? Result is a binary \textit{yes(Y\textsubscript{l})/No(N\textsubscript{l)}} decision.
\end{itemize}
This is shown in the decision-tree diagram below, where leaf nodes \textbf{Q} indicate a decision in favor of Qawali and \textbf{NQ} is the node for all other cases. Essentially it means the binary classifier categorizes a song as Qawali only in two cases: first one where both tabla and taali were detected and an additional case where taali has been detected form its feature but tabla detection was marginal. The reason is grounded in the individual source detection methods which are explained next.

\begin{forest}
[TD,
	[Y,
		[TL:Y\textsubscript{l}
			[\textbf{Q}]]
		[TL:N\textsubscript{l}
			[\textbf{NQ}]]
	]
	[N,
		[TL:Y\textsubscript{l}
			[\textbf{NQ}]]
		[TL:N\textsubscript{l}
			[\textbf{NQ}]]
	]
	[M,
		[TL:Y\textsubscript{l}
			[\textbf{Q}]]
		[TL:N\textsubscript{l}
			[\textbf{NQ}]]
	]
]
\end{forest}

For tabla detection a gaussian distribution is fitted on tabla source's CQT power as given in \ref{eq:eq6}

\begin{align}\label{eq:eq8}
\boldsymbol{f}_{CQT} \sim \mathcal{N}(\mu, \sigma^{2})
\end{align}

where $\mu \in [p_{1}, p_{2}]$ is the mean pitch within an octave band and $\sigma^{2} < T_{h}$ is the variance of pitch (measured in Hz or midi-notes). $p_{1}$, $p_{2}$ and the threshold $T_{h}$ are design parameters statically chosen at the start of the classification process. Tabla is positively detected if a guassian curve successfully fits with defined parameter ranges. As described above, tabla decision is a non binary decision, meaning that some tolerance is accpeted for gaussian curve parameters to categorize an intermediate decision.

For taali detection, given $M$ MFCC elements we attempt to find a mfcc-index $i \in (0, M-1)$ corresponding to a local extrema point i.e. either $\boldsymbol{f}_{MFCC}(i) \leq \boldsymbol{f}_{MFCC}(j)$ or $\boldsymbol{f}_{MFCC}(i) \geq \boldsymbol{f}_{MFCC}(j)$ where $j \in (m_{1}, m_{2})$. Like tabla detector above here also $m_{1}$ and $m_{2}$ are design parameters, statically assigned at the start of decision process. Taali decision is positive if such a local extrema is found otherwise a negative result is declared.

\section{Results}\label{sec:result}

The ideas of previous section have been programmed into a qawali detector. This program is based on popular MIR library librosa  \citep{brian_mcfee_2022_6097378}, it uses an open source optimization library ~\citep{newville_matthew_2014} but has no other external dependencies. The program includes steps to separate songs into tabla taali components, calculating CQT and MFCC features from these source, individual tabla, taali detection culminating in overall classification of the song as Qawali or otherwise. The proposed Qawali classifier operates on four design parameters. In this section we discuss the impact of each of these parameters in detail leading to a selection of these parameters for the final classification results across Genres.

Since the classifier detects tabla and taali components independently, we discuss the results of varying tabla detection parameters first.
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{edge}
  \caption{TablaDetection: Edge note in third octave}
\label{fig:src_edge}
\end{figure}

Next comes the impact of chosing CQT energy spread in third octave
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{o3}
  \caption{TablaDetection: CQT variance in third octave}
\label{fig:src_o3}
\end{figure}


For "Maybe" decision of Tabla detection in fourth octave we have to select a larger energy variance for guassian curve fitting. Too large a value will increase false positive and too low a value results in missed qawali detections.
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{o4}
  \caption{TablaDetection: CQT variance in fourth octave}
\label{fig:src_o4}
\end{figure}

For Taali detection we focus on finding a local extrema with the MFCC distribution of the taali source separated from the song. Based on prelimianary investigated, start and end of MFCC function was seen not be the determining factor in Qawali taali sources. The impact of on choosing local extrema point to one of 5th, 6th and 7th MFCC is shown in the figure below. Based on this hueristic 6th MFCC point was chosen to detect Taali source within the song.
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{taali_mfcc}
  \caption{TaaliDetection: MFCC local extremum impact}
\label{fig:src_mfcc}
\end{figure}

Based on above we chose the following parameters for Tabla detection, octave 3 with spread() for yes and octave 4 with (). The results of this classifier are then used to generate accuracy results per Genre shown in figure
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{genreA}
  \caption{Qawali detection per Genre}
\label{fig:src_genre}
\end{figure}

\subsection{Tables should not include}

\begin{itemize}
  \item Rotated text
  \item Colour to denote meaning (it will not display the same on all devices)
  \item Images
  \item Vertical or diagonal lines
  \item Multiple parts (e.g. ``Table 1a'' and ``Table 1b'').
  These should either be merged into one table,
  or separated into ``Table 1'' and ``Table 2''.
\end{itemize}

\begin{table}[htpb]
\centering
  \begin{tabular}{ll}
  \toprule
  \bfseries String Value & \bfseries Numeric Value \\ \midrule
  Hello ISMIR  & 2017          \\
  \bottomrule
  \end{tabular}
  \caption{Table captions should be placed below the table.}
\label{tab:table}
\end{table}


\section{Reproducibility (if applicable)}

If the content of your submission relates to data or software
that has been deposited in a code or preservation repository,
please provide summary information here, along with a DOI that
links to the deposited code/data. Add here link to github repo containing
source and code, how to arrange DOI?\endnote{Link to citation examples: \\
\url{http://transactions.ismir.net/about/submissions/\#References}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Please do not touch.
% Print Endnotes
\IfFileExists{\jobname.ent}{
   \theendnotes
}{
   %no endnotes
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

Any acknowledgements must be headed and in a separate paragraph,
placed after the main text but before the reference list.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% For bibtex users:
\bibliography{TISMIRtemplate}

% For non bibtex users:
%\begin{thebibliography}{citations}
%
%\bibitem {Author:00}
%E. Author.
%``The Title of the Conference Paper,''
%{\it Proceedings of the International Symposium
%on Music Information Retrieval}, pp.~000--111, 2000.
%
%\bibitem{Someone:10}
%A. Someone, B. Someone, and C. Someone.
%``The Title of the Journal Paper,''
%{\it Journal of New Music Research},
%Vol.~A, No.~B, pp.~111--222, 2010.
%
%\bibitem{Someone:04} X. Someone and Y. Someone. {\it Title of the Book},
%    Editorial Acme, Porto, 2012.
%
%\end{thebibliography}

\end{document}
