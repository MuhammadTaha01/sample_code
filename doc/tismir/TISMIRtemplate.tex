%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for TISMIR Papers
% 2017 version, based on previous ISMIR conference template
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sample Document LaTeX packages
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[utf8]{inputenc}
\usepackage{tismir}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{lipsum}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title and Author information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{QawalRang: A dataset for genre classification of Qawalis}
%
\author{%
Faheem Sheikh}%

\date{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Additional Paper Information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Article Type - Uncomment and modify, if necessary.
% Accepted values: research, overview, and dataset
\type{dataset}

% Citation in First Page
%
% "Mandatory" (if missing will print the complete list of authors,
% including the \thanks symbols)
\authorref{Sheikh,~F.}
%
% (Optional)
% \journalyear{2017}
% \journalvolume{V}
% \journalissue{N}
% \journalpages{xx--xx}
% \doi{xx.xxxx/xxxx.xx}

% Remaining Pages (Optional)
%
\authorshort{Sheikh, ~F.} %or, e.g., \authorshort{Author1 et al}
% \titleshort{Template for TISMIR}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document Content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\twocolumn[{%
%
\maketitleblock
%
\today
%

\begin{abstract}
A new dataset containing 64 Qawali songs of one-minute duration along with tagged metadata is presented. This dataset is used for genre detection of Qawali songs against popular western music genres. The unsupervised genre classification algorithm is based on source separation of two major components typical of Qawali performances namely tabla and taali. The algorithm shows a detection rate of almost 80\% with average false positive across other genres to be around 8\%. Dataset is accompanined with python programs used to construct and extend the dataset as well as repdrocuing the results presented in this study. \end{abstract}
%
\begin{keywords}
genre, classification, qawali, dataset, tabla, taali
\end{keywords}
}]
\saythanks{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Main Content Start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}\label{sec:intro}
Qawalis have a long and historic tradition, by some accounts they go back to at least 13th century. They have been used to recite devotional songs, have been sung by groups in shrines. Even today they are popular in Indian subcontinent with performances given on happy occassions, part of songs  in films as well as religious commemorations. 

Qawalis incorporate both classical and modern musical elements, but almost all performance are characteristed by two fold beat elements a tabla which is the primary rythym elemnet and periodic clapping by backing vocals called "taali".

Introudce genre detection as a problem, reference to MIREX tasks and literature survery of genre classification of non-western music

Review of organization of rest of the paper.

\section{Dataset}\label{sec:data}
Songs in QawalRang dataset have been source from personal collection, web-crawling and popular music streaming online platforms like youtube. The selection criterion behind including a song was based on following points.
\begin{itemize}
\item Song is performed by well-known/renowed Qawal parties/groups. This is to remove any doubts about labeleling. Ofcourse this has to traded-off against diversity of performers.
\item Songs start with a introductory section including both tabla and taali components. In a very small minority of cases where songs start with a vocal improvisation but does contains segments with tabla and taali components at a later timepoint, that snippet is included.
\item Songs performed in classical/semi-classical pattern have been preferred, this makes QawalRang dataset unique and reduces overlapp with other common genre like pop and rock. For this reason songs that follow a modern mixture of qawali with mainstream music are avoided.
\end{itemize}

All songs included in the dataset are described by a metadata file of key-value pairs. The key-values are governed by a json schema which defines the following keys:
\begin{enumerate}
\item ID: unique identifier of the song in the data-set
\item name: song's original/descriptive name
\item artist: performer's or Qawal party's name
\item location: URL for the full song
\item start: Timestamp in seconds within origianl song from where snippet was taken
\item duration: Duration of song snippet in seconds
\end{enumerate}

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0, width=0.95\columnwidth]{sources}
  \caption{QawalRang: Distribution by sources}
\label{fig:figure}
\end{figure}
Above metadata description allows easy experimentation and even extension of the dataset. Accompying the dataset is a python program which can (re)construct QawalRang dataset or a section of it by reading the metadata file on the fly. The program supports both offline and oneline modes with the former meaning that songs are not downloaded upon building the dataset
\begin{figure}[htbp]
  \centering
  \includegraphics[height=4cm, width=0.95\columnwidth]{artist}
  \caption{QawalRang: Distribution by artist/performer}
\label{fig:figure}
\end{figure}

\section{Qawali Genre Detector}\label{sec:detector}

The proposed Qawali genre detector works on the principle that most performances include segments with rythym driven by tabla and beat controlled by periodic clapping. The detector aims to separate tabla and taali components from the raw audio data, extracts CQT and MFCC features separately from the tabla/taali sources respectively. It then uses heuristics for pitch energy and local mfcc extrema points to reach a binary classification decision for qawali
\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.5, width=0.95\columnwidth]{qawali_detector}
  \caption{Qawali genre detector.}
\label{fig:figure}
\end{figure}

\subsection{Feature extraction}
Features are extracted from raw audio spectrogram after separating the audio in potential tabla/taali source spectrograms. Let $\boldsymbol{S}$ be an $txm$ audio spectrum matrix decomposed into sorted feature matrix $\boldsymbol{W}$ and coefficients matrix $\boldsymbol{H}$ each of dimensions $txn$ and $nxm$ respectively with non-negative matrix factorization, where $n$ is the number of independent music sources the song is composed of.

\begin{align}\label{eq:eq}
\boldsymbol{S} = \boldsymbol{W}.\boldsymbol{H}
\end{align}

We select $l \in (0,n)$ to extract Tabla spectrogram $\boldsymbol{S}_{B}$ 

\begin{align}\label{eq:eq}
\boldsymbol{S}_{B} = \boldsymbol{W}_{B}.\boldsymbol{H}_{B}
\end{align}
where
\begin{align}\label{eq:eq}
\boldsymbol{W}_{B} = [\boldsymbol{W}.\boldsymbol{u}_{l} ...]
\end{align}
and 
\begin{align}\label{eq:eq}
\boldsymbol{H}_{B} = [\boldsymbol{u}_{l}^T.\boldsymbol{H} ...]
\end{align}
with $u_{l}$ being a unit column vector from Identity matrix $\boldsymbol{I}$ with size $txt$. In other words spectrogram for tabla source is simply computed
by selecting columns/rows from feature matrix $\boldsymbol{H}$ and coefficient matrix $\boldsymbol{W}$. Similary taali spectrogram $\boldsymbol{S}_{T}$ can be written as:
\begin{align}\label{eq:eq}
\boldsymbol{S}_{T} = \boldsymbol{W}_{T}.\boldsymbol{H}_{T}
\end{align}

Feature-set for genre detection is then absolute CQT for the tabla source, obtained by mapping CQT from tabla spectrogram as represented by:
\begin{align}\label{eq:eq}
\boldsymbol{f}_{CQT} = \lvert f\colon \boldsymbol{S}_{B}\to CQT \rvert
\end{align}
and energy of mfcc vector mapped from taali spectrogram:
\begin{align}\label{eq:eq}
\boldsymbol{f}_{CQT} = \lvert \lvert {f\colon \boldsymbol{S}_{T}\to MFCC} \rvert \rvert
\end{align}

\subsection{Binary Classification}
We aim to make a classifier which can decide if the song represented by the features extracted from tabla and taali components represents a qawali
This section should explain the gaussian curve fitting on tabla pitch energy and local extrema detection on taali MFCCs



\section{Results}\label{sec:result}

Tables must be created using a word processor's table function,
not tabbed text.
Tables should be included in the manuscript.
The final layout will place the tables as close to their first
citation as possible.

All tables must be cited within the main text, numbered with Arabic
numerals in consecutive order (e.g. Table 1, Table 2, etc.).

Each table must have an accompanying descriptive title.
This should clearly and concisely summarise the content and/or
use of the table.
A short additional table legend is optional to offer a further
description of the table.

\subsection{Tables should not include}

\begin{itemize}
  \item Rotated text
  \item Colour to denote meaning (it will not display the same on all devices)
  \item Images
  \item Vertical or diagonal lines
  \item Multiple parts (e.g. ``Table 1a'' and ``Table 1b'').
  These should either be merged into one table,
  or separated into ``Table 1'' and ``Table 2''.
\end{itemize}

\begin{table}[htpb]
\centering
  \begin{tabular}{ll}
  \toprule
  \bfseries String Value & \bfseries Numeric Value \\ \midrule
  Hello ISMIR  & 2017          \\
  \bottomrule
  \end{tabular}
  \caption{Table captions should be placed below the table.}
\label{tab:table}
\end{table}

\section{Equations}\label{sec:equations}

Equations should be placed on separate lines and numbered.
The number should be on the right side, in parentheses,
as in Eqn.~(\ref{eq:eq}).

\begin{align}\label{eq:eq}
E = mc^2
\end{align}

\section{Reproducibility (if applicable)}

If the content of your submission relates to data or software
that has been deposited in a code or preservation repository,
please provide summary information here, along with a DOI that
links to the deposited code/data.



\section{References}

All citations must be listed at the end of the text file,
in alphabetical order of authors' surnames.
References should not be listed if they are not cited in
the main text.
This journal uses the APA system.
Please visit the journal's website
for examples of referencing format.\endnote{Link to citation examples: \\
\url{http://transactions.ismir.net/about/submissions/\#References}}

In this template, you can use \verb=\citep{}= to include references
surrounded by parentheses, such as~\citep{KneesS16_MusicSimilarityRetrieval_SPRINGER}, and \verb=\cite{}=
for references embedded in the text,
such as~\cite{WeihsJVR16_MusicDataAnalysis_CRC},
\cite{SerraEtAl13_RoadmapMIR_CreativeCommon},
\cite{Lerch15_AudioContentAnalysis_WILEY},
or~\cite{Mueller15_FMP_SPRINGER}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Please do not touch.
% Print Endnotes
\IfFileExists{\jobname.ent}{
   \theendnotes
}{
   %no endnotes
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

Any acknowledgements must be headed and in a separate paragraph,
placed after the main text but before the reference list.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% For bibtex users:
\bibliography{TISMIRtemplate}

% For non bibtex users:
%\begin{thebibliography}{citations}
%
%\bibitem {Author:00}
%E. Author.
%``The Title of the Conference Paper,''
%{\it Proceedings of the International Symposium
%on Music Information Retrieval}, pp.~000--111, 2000.
%
%\bibitem{Someone:10}
%A. Someone, B. Someone, and C. Someone.
%``The Title of the Journal Paper,''
%{\it Journal of New Music Research},
%Vol.~A, No.~B, pp.~111--222, 2010.
%
%\bibitem{Someone:04} X. Someone and Y. Someone. {\it Title of the Book},
%    Editorial Acme, Porto, 2012.
%
%\end{thebibliography}

\end{document}
